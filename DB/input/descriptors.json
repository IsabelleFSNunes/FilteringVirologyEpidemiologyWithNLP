{
    "topic virology":  [
        "virology or epidemiology",
        "virology",
        "epidemiology",
        "covid19",
        "covid",
        "pandemic",
        "epidemy",
        "virus",
        "infection",
        "contamination",
        "disease",
        "contagious disease",
        "influenza",
        "sarscov",
        "vaccination",
        "vaccine",
        "viral"
    ], 
    "machine learning": [
        "neural network",
        "artificial neural network",
        "neural net algorithm",
        "multilayer perceptron",
        "multilayer perceptron (mlp)",
        "mlp",
        "feedforward neural network",
        "recurrent neural network",
        "recurrent neural network (rnn)",
        "rnn",
        "long short-term memory network",
        "long short-term memory network (lstm)",
        "lstm",
        "convolutional neural network",
        "convolutional neural network (cnn)",
        "cnn"
    ],
    "deep learning": [
        "deep learning",
        "deep learning (dl)",
        "dl",
        "deep neural networks",
        "computer vision",
        "vision model",
        "image processing",
        "vision algorithms",
        "computer graphics and vision",
        "object recognition",
        "scene understanding",
        "language processing",
        "text analytics",
        "speech and language technology"
    ],
    "nlp": [
        "natural language processing",
        "natural language processing (nlp)",
        "nlp",
        "text mining",
        "computational linguistics",
        "language processing",
        "text analytics",
        "textual data analysis",
        "text data analysis",
        "text analysis",
        "speech and language technology",
        "language modeling",
        "computational semantics"
    ],
    "generative": [
        "generative artificial intelligence",
        "generative ai",
        "generative deep learning",
        "generative models",
        "generative dl"
    ],
    "transformer": [
        "transformer",
        "transformers models",
        "self-attention models",
        "transformer architecture",
        "attention-based neural networks",
        "transformer networks",
        "sequence-to-sequence models"
    ],
    "llm": [
        "large language model",
        "large language model (llm)",
        "llm",
        "transformer-based model",
        "pretrained language model",
        "pre-trained language model",
        "generative language model",
        "foundation model",
        "state-of-the-art language model"
    ],
    "multimodal": [
        "multimodal model",
        "multimodal neural network",
        "diffusion model",
        "generative diffusion model",
        "diffusion-based generative model",
        "continuous diffusion model"
    ],
    "vision": [
        "vision",
        "visual",
        "vision transformer",
        "vision model",
        "image processing",
        "vision algorithms",
        "computer graphics and vision",
        "object recognition",
        "scene understanding",
        "classification of images",
        "image classification",
        "image smoothing"
    ],
    "techniques": [
        "generative",
        "transformer",
        "multimodal",
        "image classification",
        "diffusion",
        "llm",
        "language large model",
        "nlp",
        "natural language processing",
        "natural language processing (nlp)",
        "nlp",
        "feedforward neural network",
        "recurrent neural network",
        "recurrent neural network (rnn)",
        "rnn",
        "long short-term memory network",
        "long short-term memory network (lstm)",
        "lstm",
        "convolutional neural network",
        "convolutional neural network (cnn)",
        "cnn",
        "encoder",
        "decoder",
        "generative adversarial network",
        "generative adversarial network (gan)",
        "ensemble",
        "fine-tuning",
        "bert",
        "gpt",
        "llama"
    ]
}
